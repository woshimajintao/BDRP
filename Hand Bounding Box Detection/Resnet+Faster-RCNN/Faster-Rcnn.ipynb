{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3df0acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.transforms import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, average_precision_score\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639b4c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "# Configuration parameters\n",
    "class Config:\n",
    "    # Path configuration\n",
    "    DATA_ROOT = \"D:/Code_pytorch/Jintao/hand detection\"\n",
    "    TRAIN_IMAGES = os.path.join(DATA_ROOT, \"training_dataset/training_dataset/training_data/images\")\n",
    "    TRAIN_LABELS = os.path.join(DATA_ROOT, \"labels_fast_rcnn\")\n",
    "    TEST_IMAGES = os.path.join(DATA_ROOT, \"training_dataset/training_dataset/training_data/images\")\n",
    "    TEST_LABELS = os.path.join(DATA_ROOT, \"labels_fast_rcnn\")\n",
    "    OUTPUT_DIR = os.path.join(DATA_ROOT, \"output\")\n",
    "    MODEL_SAVE_PATH = os.path.join(OUTPUT_DIR, \"faster_rcnn_model.pth\")\n",
    "    \n",
    "    # Training parameters\n",
    "    NUM_CLASSES = 2  # Background + number of target classes\n",
    "    BATCH_SIZE = 10\n",
    "    NUM_EPOCHS = 20\n",
    "    LEARNING_RATE = 0.005\n",
    "    MOMENTUM = 0.9\n",
    "    WEIGHT_DECAY = 0.0005\n",
    "    \n",
    "    # Device configuration\n",
    "    DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3c4137",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Custom dataset class\n",
    "class HandDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir, train=False, transforms=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.transforms = transforms\n",
    "        self.train = train\n",
    "        self.image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        original_width, original_height = image.size\n",
    "        \n",
    "        # Resize image to 112x112\n",
    "        new_size = (112, 112)\n",
    "        image = F.resize(image, new_size)\n",
    "        \n",
    "        # Calculate scaling factor\n",
    "        width_scale = new_size[0] / original_width\n",
    "        height_scale = new_size[1] / original_height\n",
    "        \n",
    "        # Load labels\n",
    "        label_path = os.path.join(self.label_dir, os.path.splitext(img_name)[0] + \".txt\")\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        \n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) != 5:\n",
    "                    continue\n",
    "                \n",
    "                class_id = int(parts[0])\n",
    "                x_min = float(parts[1])\n",
    "                y_min = float(parts[2])\n",
    "                x_max = float(parts[3])\n",
    "                y_max = float(parts[4])\n",
    "                \n",
    "                # Scale coordinates\n",
    "                x_min = x_min * width_scale\n",
    "                y_min = y_min * height_scale\n",
    "                x_max = x_max * width_scale\n",
    "                y_max = y_max * height_scale\n",
    "                \n",
    "                boxes.append([x_min, y_min, x_max, y_max])\n",
    "                labels.append(class_id + 1)  # 0 reserved for background\n",
    "\n",
    "        # Convert to tensors\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        \n",
    "        # Data augmentation: random horizontal flip\n",
    "        if self.train and random.random() < 0.5:\n",
    "            image = F.hflip(image)\n",
    "            boxes[:, [0, 2]] = 112 - boxes[:, [2, 0]]\n",
    "\n",
    "        image = F.to_tensor(image)\n",
    "\n",
    "        target = {\n",
    "            \"boxes\": boxes,\n",
    "            \"labels\": labels,\n",
    "            \"image_id\": torch.tensor([idx]),\n",
    "            \"area\": (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0]),\n",
    "            \"iscrowd\": torch.zeros((len(boxes),), dtype=torch.int64)\n",
    "        }\n",
    "\n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "\n",
    "        return image, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deace115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "def create_model(num_classes):\n",
    "    # Load the ResNet-50 backbone pretrained on ImageNet\n",
    "    backbone = torchvision.models.resnet50(pretrained=True)\n",
    "    backbone = torch.nn.Sequential(*list(backbone.children())[:-2])  # Remove the fully connected layers\n",
    "    backbone.out_channels = 2048  # Set the output channels to match ResNet-50's feature map output\n",
    "    \n",
    "    # Define anchor generator\n",
    "    anchor_generator = AnchorGenerator(\n",
    "        sizes=((16, 32, 64, 128, 256),),  # Define anchor box sizes\n",
    "        aspect_ratios=((0.5, 1.0, 2.0),)  # Define aspect ratios\n",
    "    )  \n",
    "    \n",
    "    # Define ROI (Region of Interest) Pooling\n",
    "    roi_pooler = torchvision.ops.MultiScaleRoIAlign(\n",
    "        featmap_names=['0'],  # Feature map name (Faster R-CNN uses only one level of feature map)\n",
    "        output_size=7,  # Output size for the pooled feature map\n",
    "        sampling_ratio=2  # Sampling ratio for RoIAlign\n",
    "    )\n",
    "    \n",
    "    # Construct Faster R-CNN model\n",
    "    model = FasterRCNN(\n",
    "        backbone,\n",
    "        num_classes=num_classes,  # Number of object classes (including background)\n",
    "        rpn_anchor_generator=anchor_generator,  # Use the defined anchor generator\n",
    "        box_roi_pool=roi_pooler  # Use the defined ROI pooling layer\n",
    "    )\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c8a243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IoU (Intersection over Union) computation function\n",
    "def calculate_iou(boxA, boxB):\n",
    "    # Compute the coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    \n",
    "    # Compute the area of intersection\n",
    "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "    \n",
    "    # Compute the area of both bounding boxes\n",
    "    boxAArea = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
    "    boxBArea = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
    "    \n",
    "    # Compute the union area\n",
    "    unionArea = boxAArea + boxBArea - interArea\n",
    "    \n",
    "    # Compute the IoU (return 0 if unionArea is zero to avoid division by zero)\n",
    "    return interArea / unionArea if unionArea != 0 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431f79b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function (with loss tracking)\n",
    "def train_model(model, train_loader, optimizer, lr_scheduler, num_epochs):\n",
    "    model.train()\n",
    "    train_losses = []  # Store loss values for each epoch\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0  # Initialize epoch loss\n",
    "        \n",
    "        for images, targets in train_loader:\n",
    "            # Move images and targets to the configured device (GPU/CPU)\n",
    "            images = list(image.to(Config.DEVICE) for image in images)\n",
    "            targets = [{k: v.to(Config.DEVICE) for k, v in t.items()} for t in targets]\n",
    "\n",
    "            # Compute loss\n",
    "            loss_dict = model(images, targets)\n",
    "            losses = sum(loss for loss in loss_dict.values())\n",
    "\n",
    "            # Backpropagation and optimization\n",
    "            optimizer.zero_grad()\n",
    "            losses.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += losses.item()\n",
    "        \n",
    "        # Compute average loss for the epoch\n",
    "        epoch_loss /= len(train_loader)\n",
    "        train_losses.append(epoch_loss)\n",
    "        \n",
    "        # Update learning rate scheduler\n",
    "        lr_scheduler.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} Loss: {epoch_loss:.4f}\")\n",
    "    \n",
    "    return train_losses  # Return recorded losses for analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb9d4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function (improved metric computation)\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []  # Store all predictions\n",
    "    all_targets = []  # Store all ground truth targets\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets in test_loader:\n",
    "            # Move images to the configured device (GPU/CPU)\n",
    "            images = list(img.to(Config.DEVICE) for img in images)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            for i, output in enumerate(outputs):\n",
    "                # Extract predicted bounding boxes, labels, and confidence scores\n",
    "                pred_boxes = output['boxes'].cpu().numpy()\n",
    "                pred_labels = output['labels'].cpu().numpy()\n",
    "                pred_scores = output['scores'].cpu().numpy()\n",
    "                \n",
    "                # Extract ground truth bounding boxes and labels\n",
    "                target_boxes = targets[i]['boxes'].cpu().numpy()\n",
    "                target_labels = targets[i]['labels'].cpu().numpy()\n",
    "                \n",
    "                # Store predictions and ground truths for metric computation\n",
    "                all_preds.append((pred_boxes, pred_labels, pred_scores))\n",
    "                all_targets.append((target_boxes, target_labels))\n",
    "    \n",
    "    # Compute evaluation metrics\n",
    "    precision, recall, ap = calculate_metrics(all_preds, all_targets)\n",
    "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, AP: {ap:.4f}\")\n",
    "    \n",
    "    return precision, recall, ap  # Return computed metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ece8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Compute evaluation metrics\n",
    "def calculate_metrics(preds, targets, iou_threshold=0.5):\n",
    "    scores_list = []\n",
    "    tp_list = []\n",
    "    fp_list = []\n",
    "    total_gt = 0  # Total number of ground truth boxes\n",
    "    \n",
    "    for (pred_boxes, pred_labels, pred_scores), (gt_boxes, gt_labels) in zip(preds, targets):\n",
    "        # Process only class 1 predictions\n",
    "        valid_mask = pred_labels == 1\n",
    "        pred_boxes = pred_boxes[valid_mask]\n",
    "        pred_scores = pred_scores[valid_mask]\n",
    "        \n",
    "        # Sort predictions by confidence score in descending order\n",
    "        sorted_indices = np.argsort(-pred_scores)\n",
    "        pred_boxes = pred_boxes[sorted_indices]\n",
    "        pred_scores = pred_scores[sorted_indices]\n",
    "        \n",
    "        # Initialize matching status\n",
    "        gt_matched = np.zeros(len(gt_boxes), dtype=bool)\n",
    "        tp = np.zeros(len(pred_boxes), dtype=int)\n",
    "        fp = np.zeros(len(pred_boxes), dtype=int)\n",
    "        \n",
    "        for i, pred_box in enumerate(pred_boxes):\n",
    "            best_iou = 0.0\n",
    "            best_gt = -1\n",
    "            \n",
    "            for j, gt_box in enumerate(gt_boxes):\n",
    "                if gt_matched[j]:  # Skip already matched ground truth boxes\n",
    "                    continue\n",
    "                iou = calculate_iou(pred_box, gt_box)\n",
    "                if iou > best_iou:\n",
    "                    best_iou = iou\n",
    "                    best_gt = j\n",
    "            \n",
    "            # Match prediction with ground truth if IoU is above threshold\n",
    "            if best_iou >= iou_threshold and best_gt != -1:\n",
    "                tp[i] = 1\n",
    "                gt_matched[best_gt] = True  # Mark ground truth as matched\n",
    "            else:\n",
    "                fp[i] = 1  # False positive\n",
    "        \n",
    "        scores_list.extend(pred_scores)\n",
    "        tp_list.extend(tp)\n",
    "        fp_list.extend(fp)\n",
    "        total_gt += len(gt_boxes)\n",
    "    \n",
    "    # Convert lists to arrays and sort by confidence score\n",
    "    scores = np.array(scores_list)\n",
    "    tp = np.array(tp_list)\n",
    "    fp = np.array(fp_list)\n",
    "    \n",
    "    indices = np.argsort(-scores)\n",
    "    tp = tp[indices]\n",
    "    fp = fp[indices]\n",
    "    \n",
    "    # Compute cumulative metrics\n",
    "    cum_tp = np.cumsum(tp)\n",
    "    cum_fp = np.cumsum(fp)\n",
    "    \n",
    "    precision = cum_tp / (cum_tp + cum_fp + 1e-6)  # Avoid division by zero\n",
    "    recall = cum_tp / (total_gt + 1e-6)\n",
    "    \n",
    "    # Compute mAP (PASCAL VOC style)\n",
    "    ap = 0.0\n",
    "    for t in np.arange(0., 1.1, 0.1):\n",
    "        mask = recall >= t\n",
    "        if np.any(mask):\n",
    "            ap += np.max(precision[mask]) / 11  # Average precision over recall levels\n",
    "    \n",
    "    # Final precision and recall values\n",
    "    final_precision = cum_tp[-1] / (cum_tp[-1] + cum_fp[-1]) if (cum_tp[-1] + cum_fp[-1]) > 0 else 0\n",
    "    final_recall = cum_tp[-1] / total_gt if total_gt > 0 else 0\n",
    "    \n",
    "    return final_precision, final_recall, ap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118b9558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize prediction results\n",
    "def visualize_predictions(model, test_loader, num_images=3):\n",
    "    model.eval()\n",
    "    images, targets = next(iter(test_loader))  # Get a batch of test images\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Move images to the configured device (GPU/CPU)\n",
    "        images = list(img.to(Config.DEVICE) for img in images)\n",
    "        outputs = model(images)  # Get model predictions\n",
    "    \n",
    "    for i in range(min(num_images, len(images))):\n",
    "        # Convert tensor image to NumPy array\n",
    "        img = images[i].cpu().permute(1, 2, 0).numpy()\n",
    "        img = (img * 255).astype(np.uint8)  # Convert to 8-bit format\n",
    "        img = Image.fromarray(img)  # Convert to PIL image\n",
    "        \n",
    "        draw = ImageDraw.Draw(img)\n",
    "        \n",
    "        # Ground truth bounding boxes (Green)\n",
    "        for box in targets[i]['boxes']:\n",
    "            draw.rectangle(box.tolist(), outline=(0, 255, 0), width=2)\n",
    "        \n",
    "        # Predicted bounding boxes (Red)\n",
    "        for box in outputs[i]['boxes'].cpu().numpy():\n",
    "            draw.rectangle(box.tolist(), outline=(255, 0, 0), width=2)\n",
    "        \n",
    "        # Display image\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(f\"Predictions (Red) vs Ground Truth (Green)\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfde7bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss curve\n",
    "def plot_loss_curve(train_losses):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(train_losses, label='Training Loss')  # Plot the training loss\n",
    "    plt.xlabel('Epoch')  # X-axis label\n",
    "    plt.ylabel('Loss')  # Y-axis label\n",
    "    plt.title('Training Loss Curve')  # Title of the plot\n",
    "    plt.legend()  # Show legend\n",
    "    plt.savefig(os.path.join(Config.OUTPUT_DIR, 'loss_curve.png'))  # Save the loss curve as an image\n",
    "    plt.show()  # Display the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b9589d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main program\n",
    "def main():\n",
    "    os.makedirs(Config.OUTPUT_DIR, exist_ok=True)  # Create output directory if it doesn't exist\n",
    "    \n",
    "    # Prepare datasets\n",
    "    train_dataset = HandDataset(\n",
    "        Config.TRAIN_IMAGES,\n",
    "        Config.TRAIN_LABELS,\n",
    "        train=True\n",
    "    )\n",
    "    \n",
    "    test_dataset = HandDataset(\n",
    "        Config.TEST_IMAGES,\n",
    "        Config.TEST_LABELS\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=Config.BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        collate_fn=lambda x: tuple(zip(*x)))  # Handle variable-sized targets\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=Config.BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        collate_fn=lambda x: tuple(zip(*x)))\n",
    "    \n",
    "    # Initialize the model\n",
    "    model = create_model(Config.NUM_CLASSES)\n",
    "    model.to(Config.DEVICE)\n",
    "    \n",
    "    # Define optimizer\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(\n",
    "        params,\n",
    "        lr=Config.LEARNING_RATE,\n",
    "        momentum=Config.MOMENTUM,\n",
    "        weight_decay=Config.WEIGHT_DECAY\n",
    "    )\n",
    "    \n",
    "    # Learning rate scheduler\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "        optimizer,\n",
    "        step_size=5,\n",
    "        gamma=0.1\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    print(\"Starting training...\")\n",
    "    train_losses = train_model(model, train_loader, optimizer, lr_scheduler, Config.NUM_EPOCHS)\n",
    "    \n",
    "    # Plot the loss curve\n",
    "    plot_loss_curve(train_losses)\n",
    "    \n",
    "    # Save the trained model\n",
    "    torch.save(model.state_dict(), Config.MODEL_SAVE_PATH)\n",
    "    print(f\"Model saved at {Config.MODEL_SAVE_PATH}\")\n",
    "    \n",
    "    # Evaluate the model\n",
    "    print(\"\\nEvaluating on the test set...\")\n",
    "    precision, recall, ap = evaluate(model, test_loader)\n",
    "    print(f\"Final evaluation results:\\nPrecision: {precision:.4f}, Recall: {recall:.4f}, AP: {ap:.4f}\")\n",
    "    \n",
    "    # Visualize predictions\n",
    "    print(\"\\nGenerating prediction visualizations...\")\n",
    "    visualize_predictions(model, test_loader)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_py39",
   "language": "python",
   "name": "env_py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
