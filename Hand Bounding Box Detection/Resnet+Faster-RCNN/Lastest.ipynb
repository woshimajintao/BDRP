{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3df0acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.transforms import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_score, recall_score, average_precision_score\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "639b4c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration parameters\n",
    "class Config:\n",
    "    # Path configuration\n",
    "    DATA_ROOT = \"D:/Code_pytorch/xianyu/hand detection\"\n",
    "    TRAIN_IMAGES = os.path.join(DATA_ROOT, \"training_dataset/training_dataset/training_data/images\")\n",
    "    TRAIN_LABELS = os.path.join(DATA_ROOT, \"labels_fast_rcnn\")\n",
    "    TEST_IMAGES = os.path.join(DATA_ROOT, \"training_dataset/training_dataset/training_data/images\")\n",
    "    TEST_LABELS = os.path.join(DATA_ROOT, \"labels_fast_rcnn\")\n",
    "    OUTPUT_DIR = os.path.join(DATA_ROOT, \"output\")\n",
    "    MODEL_SAVE_PATH = os.path.join(OUTPUT_DIR, \"faster_rcnn_model.pth\")\n",
    "    \n",
    "    # Training parameters\n",
    "    NUM_CLASSES = 2  # Background + target class count\n",
    "    BATCH_SIZE = 10\n",
    "    NUM_EPOCHS = 20\n",
    "    LEARNING_RATE = 0.005\n",
    "    MOMENTUM = 0.9\n",
    "    WEIGHT_DECAY = 0.0005\n",
    "    \n",
    "    # Device configuration\n",
    "    DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc3c4137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class\n",
    "class HandDataset(Dataset):\n",
    "    def __init__(self, image_dir, label_dir, train=False, transforms=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.transforms = transforms\n",
    "        self.train = train\n",
    "        self.image_files = [f for f in os.listdir(image_dir) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        img_name = self.image_files[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        original_width, original_height = image.size\n",
    "        \n",
    "        # Resize image to 112x112\n",
    "        new_size = (112, 112)\n",
    "        image = F.resize(image, new_size)\n",
    "        \n",
    "        # Compute scale ratios\n",
    "        width_scale = new_size[0] / original_width\n",
    "        height_scale = new_size[1] / original_height\n",
    "        \n",
    "        # Load labels\n",
    "        label_path = os.path.join(self.label_dir, os.path.splitext(img_name)[0] + \".txt\")\n",
    "        boxes = []\n",
    "        labels = []\n",
    "        \n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split()\n",
    "                if len(parts) != 5:\n",
    "                    continue\n",
    "                \n",
    "                class_id = int(parts[0])\n",
    "                x_min = float(parts[1])\n",
    "                y_min = float(parts[2])\n",
    "                x_max = float(parts[3])\n",
    "                y_max = float(parts[4])\n",
    "                \n",
    "                # Scale coordinates\n",
    "                x_min = x_min * width_scale\n",
    "                y_min = y_min * height_scale\n",
    "                x_max = x_max * width_scale\n",
    "                y_max = y_max * height_scale\n",
    "                \n",
    "                boxes.append([x_min, y_min, x_max, y_max])\n",
    "                labels.append(class_id + 1)  # 0 reserved for background\n",
    "        \n",
    "        # Convert to tensor\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        \n",
    "        # Data augmentation: Random horizontal flip\n",
    "        if self.train and random.random() < 0.5:\n",
    "            image = F.hflip(image)\n",
    "            boxes[:, [0, 2]] = 112 - boxes[:, [2, 0]]\n",
    "        \n",
    "        image = F.to_tensor(image)\n",
    "        \n",
    "        target = {\n",
    "            \"boxes\": boxes,\n",
    "            \"labels\": labels,\n",
    "            \"image_id\": torch.tensor([idx]),\n",
    "            \"area\": (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0]),\n",
    "            \"iscrowd\": torch.zeros((len(boxes),), dtype=torch.int64)\n",
    "        }\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        \n",
    "        return image, target"
   ]
  }
 ]
}
